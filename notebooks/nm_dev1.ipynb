{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Near Miss Development: V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\donav\\OneDrive\\Desktop\\Gatech\\Research\\GRA Ford Research\\Near Miss Algorithm Development\\near_miss_env\\lib\\site-packages\\mass_ts\\_mass_ts.py:17: UserWarning: GPU support will not work. You must pip install mass-ts[gpu].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import mass_ts as mts\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "%matplotlib inline\n",
    "\n",
    "PLACE_HOLDER = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "source": [
    "## Begin Near Miss Development Here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearmiss_dist_v1(x, y, k):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    x : Long time series data (numpy array)\n",
    "    y : Query sequence (numpy array)  \n",
    "    k : Size of pieces, preferably a power of two (int)\n",
    "    \n",
    "    Returns:\n",
    "    dist : Distance profile (numpy array)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development V1 Objective:\n",
    "- Account for scale of certain features (i.e. acceleration, lateral velocity. etc. )\n",
    "\n",
    "## Proposition:\n",
    "- Create a mass function for unnormalized comparisons between queries and trips\n",
    "- Compute the Normalized (Pattern Influence) and Unnormalized (Scale Influence) distance function for each feature\n",
    "- Combined distance function for each feature: D_combined = w_pattern * D_normalized + w_scale * D_unnormalized\n",
    "- This will create a matrix of weights for each feature which can be initialized through domain knowledge, and then fine-tuned through cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized Mass Function:\n",
    "- Reimplementation of MASS V3 --> Lets call it: Near-miss Shape Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate distance profile using Near-miss Shape Profile (MASS V3)\n",
    "def nm_shape(x, y, k):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    x : numpy array\n",
    "        Long time series data\n",
    "    y : numpy array\n",
    "        Query sequence\n",
    "    k : int\n",
    "        Size of pieces, preferably a power of two\n",
    "    \n",
    "    Returns:\n",
    "    dist : numpy array\n",
    "        Distance profile\n",
    "    \"\"\"\n",
    "    # Length of query and data\n",
    "    m = len(y)\n",
    "    n = len(x)\n",
    "    dist = []\n",
    "\n",
    "    # Compute statistics for the query y\n",
    "    meany = np.mean(y)\n",
    "    sigmay = np.std(y, ddof=0)\n",
    "\n",
    "    # Avoid divide by zero by ensuring sigmay is non-zero\n",
    "    if sigmay == 0:\n",
    "        sigmay = 1e-10\n",
    "\n",
    "    # Compute moving mean and standard deviation for x\n",
    "    meanx = np.convolve(x, np.ones(m), 'valid') / m\n",
    "    sum_sq = np.convolve(x ** 2, np.ones(m), 'valid')\n",
    "    sigmax = np.sqrt((sum_sq - m * meanx ** 2) / m)\n",
    "\n",
    "    # Replace zeros in sigmax to avoid divide by zero\n",
    "    sigmax[sigmax == 0] = 1e-10\n",
    "\n",
    "    # Reverse the query and pad with zeros to match size k\n",
    "    y = y[::-1]\n",
    "    y = np.concatenate((y, np.zeros(k - m)))\n",
    "\n",
    "    # Loop through segments of the time series\n",
    "    for j in range(0, n - k + 1, k - m + 1):\n",
    "        # Get segment from x and compute FFTs\n",
    "        X = np.fft.fft(x[j:j + k])\n",
    "        Y = np.fft.fft(y)\n",
    "\n",
    "        # Element-wise multiplication in frequency domain and inverse FFT\n",
    "        Z = X * Y\n",
    "        z = np.fft.ifft(Z)\n",
    "\n",
    "        # Compute distance profile for the segment\n",
    "        d = 2 * (m - (z[m - 1:k] - m * meanx[j:j + k - m + 1] * meany) / (sigmax[j:j + k - m + 1] * sigmay))\n",
    "        dist.extend(np.sqrt(np.real(d)))\n",
    "\n",
    "    # Handle the last segment if it is longer than the query\n",
    "    j = j + k - m\n",
    "    remaining_length = n - j\n",
    "    if remaining_length >= m:\n",
    "        # Get the remaining segment from x and adjust query size\n",
    "        X = np.fft.fft(x[j:])\n",
    "        y = y[:remaining_length]\n",
    "        Y = np.fft.fft(y)\n",
    "\n",
    "        # Element-wise multiplication in frequency domain and inverse FFT\n",
    "        Z = X * Y\n",
    "        z = np.fft.ifft(Z)\n",
    "\n",
    "        # Compute distance profile for the remaining segment\n",
    "        d = 2 * (m - (z[m - 1:remaining_length] - m * meanx[j:j + remaining_length - m + 1] * meany) / (sigmax[j:j + remaining_length - m + 1] * sigmay))\n",
    "        dist.extend(np.sqrt(np.real(d)))\n",
    "\n",
    "    return np.array(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unnormalized Mass Function:\n",
    "- Similar to MASS however it doesn't z-normalize, therefor it accounts for scale\n",
    "- Lets call this Near-Miss Scale Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nm_scale(x, y, k):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    x : numpy array\n",
    "        Long time series data\n",
    "    y : numpy array\n",
    "        Query sequence\n",
    "    k : int\n",
    "        Size of pieces, preferably a power of two\n",
    "    \n",
    "    Returns:\n",
    "    dist : numpy array\n",
    "        Unnormalized distance profile\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    y = y[::-1]\n",
    "    y = np.concatenate((y, np.zeros(k - m)))\n",
    "\n",
    "    dist = []\n",
    "    for j in range(0, len(x) - k + 1, k - m + 1):\n",
    "        X = np.fft.fft(x[j:j + k])\n",
    "        Y = np.fft.fft(y)\n",
    "        Z = X * Y\n",
    "        z = np.fft.ifft(Z)\n",
    "        d = np.sqrt(np.real(z[m - 1:k]))\n",
    "        dist.extend(d)\n",
    "    \n",
    "    return np.array(dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for determining the optimal value for k (number of pieces):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_k(n, m):\n",
    "    \"\"\"\n",
    "    Determines the optimal value of k for MASS V3.\n",
    "    \n",
    "    Parameters:\n",
    "    n : Length of the time series (int) \n",
    "    m : Length of the query (int)\n",
    "\n",
    "    Returns:\n",
    "    k : Optimal segment size, preferably a power of two (int)\n",
    "    \"\"\"\n",
    "    # Set k to be the next power of two greater than or equal to 4 times the query length\n",
    "    k = 2 ** int(np.ceil(np.log2(max(4 * m, m))))\n",
    "    # Ensure k is not greater than the length of the time series\n",
    "    k = min(k, n)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the query and trip data (1 query and 1 trip)\n",
    "x = pd.read_csv(r'C:\\Users\\donav\\OneDrive\\Desktop\\Gatech\\Research\\GRA Ford Research\\Near Miss Algorithm Development\\data\\x_trip_5109.csv')\n",
    "y = pd.read_csv(r'C:\\Users\\donav\\OneDrive\\Desktop\\Gatech\\Research\\GRA Ford Research\\Near Miss Algorithm Development\\data\\y_query_7.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the optimal segment size\n",
    "n = len(x)\n",
    "m = len(y)\n",
    "k = determine_k(n, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The initial columns to compare in the time series data\n",
    "columns = ['veh_long_vel_mps', 'veh_accel_mps2_analytical', 'veh_ltrl_vel_mps', 'veh_yaw_rate_radps', 'veh_jerk_mps3_analytical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial weights for each feature\n",
    "\n",
    "weights = {\n",
    "'veh_long_vel_mps': {'w_pattern': 0.6, 'w_scale': 0.4},\n",
    "'veh_accel_mps2_analytical': {'w_pattern': 0.5, 'w_scale': 0.5},\n",
    "'veh_ltrl_vel_mps': {'w_pattern': 0.7, 'w_scale': 0.3},\n",
    "'veh_yaw_rate_radps': {'w_pattern': 0.4, 'w_scale': 0.6},\n",
    "'veh_jerk_mps3_analytical': {'w_pattern': 0.5, 'w_scale': 0.5}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Description: This test is for my (Donaven Lobo) MASS V3 implementation\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Initialize combined distance profile for the first feature\n",
    "\n",
    "feature_name = columns[0]\n",
    "w_pattern = weights[feature_name]['w_pattern']\n",
    "w_scale = weights[feature_name]['w_scale']\n",
    "combined_distance_profile = (w_pattern * nm_shape(x[feature_name].values, y[feature_name].values, k) +\n",
    "w_scale * nm_scale(x[feature_name].values, y[feature_name].values, k))\n",
    "\n",
    "Loop through each column and compute the distance profile for remaining features\n",
    "\n",
    "for col in columns[1:]:\n",
    "w_pattern = weights[col]['w_pattern']\n",
    "w_scale = weights[col]['w_scale']\n",
    "distance_profile_shape = nm_shape(x[col].values, y[col].values, k)\n",
    "distance_profile_scale = nm_scale(x[col].values, y[col].values, k)\n",
    "combined_distance_profile += (w_pattern * distance_profile_shape + w_scale * distance_profile_scale)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m114"
  },
  "kernelspec": {
   "display_name": "near_miss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
